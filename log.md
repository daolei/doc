这个文档专门用来写日志用的  
#### 2017年3月10日
  1. 今天monitor后台pg数据库节点扩容，需要修改admonitor的数据库配置文件
  2. 画workflow流程图
  3. 编写上一次事故处理文档  
#### 2017年3月11日  
  1. 今天早晨醒来发现admonitor发了很多报警信息，原来是昨天修改的配置文件发生修改错了，原来是想修改pgPartition文件，由于操作失误导致修复制回去把drPartition文件给冲了。导致整个admonitor系统无法正常出报告。后来经过二哥的处理，把原来的配置文件考回来，修复了bug。
  2. 教训： 以后一定要细心，线上操作有风险！！！！！！！
#### 2017年3月13日 周一
  1. 今天上午开组会，讲了上周做的事情。
  2. 看workflow源代码
  3. 学习shell
#### 2017年3月14日 周二 
1.今天admonitor线上有出现情况。
原因：由于Hadoop集群挂机时，admonitor正在开始做dm, oozie认为dm工作流已经挂掉，oozie就开始重启dm服务 生成dm_1，但是hadoop在挂掉以后也准备开始重启，当他跳到一个新的节点时，发现那个节点也没启动，所以hadoop集群又跳回原来的节点，不知道什么原因原来的dm_0又开始执行，这样两个dm同时执行，并向同一个目录中写入数据导致，导致数据生成的本来需要生成64个数据片的文件个数不对，变少了。而且在流程dm中并没有检查文件个数的机制。所以以后生成的报表全都有错误。  
处理办法：重算当天的活动（又是需要重算！！！！）
   在dm中加入判断文件个数的验证代码
   在流控中设置dm的retry次数为1
        今天工作，参与了恢复工作，写了重算需要的caid的脚本，学习了dm的代码！知道了dm中mr的过程。
#### 2017年3月15日 周三
1.今天开始看etl
#### 2017年3月16日 周四
 1.今天给腾讯跑的报告，是算相交样本量的
 由于集群资源突然很紧张,导致到了晚上才计算完成所有的报表  
总结：
1. 写的脚本过于繁琐，完全可以写到一个脚本里面提交上去让他自己跑，不用在旁边等着结果  
2. 经常一不小心会重新执行一遍，导致刚才算的结果又没了，又得重新跑，他娘的！！！
#### 2017年3月17日 周五
1.  写个脚本，查看数量
2.  梳理workflow的文件架构
#### 2017年3月20日 周一
1. 昨天跑top50的报告  
在跑报告的过程中在80服务器上，开了60个线程来跑，结果由于每个线程占用1G的内存导致80服务器的内存爆满，其他用户无法登陆该机器。所以以后再跑程序的时候要考虑机器本身的内存，不能随便开多线程，最好能再集群上跑。也可以写个小顶堆。
2. 继续梳理workflow的框架  
####2017年3月21日 周二
1. 提交monitor错误恢复的第一版  
2. 修该workflow 开始搭建测试环境。  
目前主要的任务是搭建oozie测试环境！！
####2017-03-22 周三
1. 上周跑任务

#### 2917-03-27 周一  
#### 2017-03-28 周二  
今天跑了个二次开发报告  
本来etl能上线的。
#### 2017-03-29 周三
休假回家考驾
#### 2017-03-30 周四
 看贝叶斯
